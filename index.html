<html>
  <head>
    <!-- Load TensorFlow.js -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@0.11.7"></script>
    <!-- Load Posenet -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/posenet@0.1.2"></script>
    <!--
	   Ideally these elements aren't created until it's confirmed that the
	   client supports video/camera, but for the sake of illustrating the
	   elements involved, they are created with markup (not JavaScript)
    -->
    <video id="video" width="640" height="480" autoplay></video>
    <canvas id="canvas" width="640" height="480"></canvas>
  </head>
  <body>
    <p>LEFT WRIST X POS</p>
		<p id="LWX">A</p>
		<p>LEFT WRIST Y POS</p>
		<p id="LWY">B</p>
		<p>RIGHT WRIST X POS</p>
		<p id="RWX">C</p>
		<p>RIFHT WRIST Y POS</p>
		<p id="RWY">D</p>
    <script>
    // Grab elements, create settings, etc.
    var video = document.getElementById('video');

    // Get access to the camera!
    if(navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
      // Not adding `{ audio: true }` since we only want video now
      navigator.mediaDevices.getUserMedia({ video: true }).then(function(stream) {
        video.src = window.URL.createObjectURL(stream);
        video.play();
      });
    }

    else if(navigator.getUserMedia) { // Standard
      navigator.getUserMedia({ video: true }, function(stream) {
        video.src = stream;
        video.play();
      }, errBack);
    } else if(navigator.webkitGetUserMedia) { // WebKit-prefixed
      navigator.webkitGetUserMedia({ video: true }, function(stream){
        video.src = window.webkitURL.createObjectURL(stream);
        video.play();
      }, errBack);
    } else if(navigator.mozGetUserMedia) { // Mozilla-prefixed
        navigator.mozGetUserMedia({ video: true }, function(stream){
          video.src = window.URL.createObjectURL(stream);
          video.play();
      }, errBack);
    }

    // Elements for taking the snapshot
    var canvas = document.getElementById('canvas');
    var context = canvas.getContext('2d');
    var video = document.getElementById('video');

    var imageScaleFactor = 0.5;
    var outputStride = 16;
    var flipHorizontal = false;

    // Trigger photo take
    setInterval(function() {
      context.drawImage(video, 0, 0, 640, 480);
      var imageElement = document.getElementById('canvas');

      posenet.load().then(function(net){
        return net.estimateSinglePose(imageElement, imageScaleFactor, flipHorizontal, outputStride)
      }).then(function(pose){
        console.log(pose);
  			document.getElementById('LWX').innerHTML=parseInt((pose.keypoints[9].position.x)/1);
  			document.getElementById('LWY').innerHTML=parseInt((pose.keypoints[9].position.y)/1);
  			document.getElementById('RWX').innerHTML=parseInt((pose.keypoints[10].position.x)/1);
  			document.getElementById('RWY').innerHTML=parseInt((pose.keypoints[10].position.y)/1);
      })
    }, 150);

    </script>
  </body>
</html>
